{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "4a4d0425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6308dbf7",
   "metadata": {},
   "source": [
    "## 학습용 데이터\n",
    "### 데이터 불러오기 + Resize하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "de43b911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "\n",
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "        \n",
    "    print(len(images), \" images resized.\")\n",
    "    \n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "1d36837f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "\n",
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "        \n",
    "    print(len(images), \" images resized.\")\n",
    "    \n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "7886092a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "\n",
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "        \n",
    "    print(len(images), \" images resized.\")\n",
    "    \n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81c257e",
   "metadata": {},
   "source": [
    "### 폴더 별 라벨링 & 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "a15167e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (210, 28, 28, 3)\n",
      "y_train shape: (210,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(img_path, number_of_data=300):\n",
    "    img_size=28\n",
    "    color=3\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img  \n",
    "        labels[idx]=0  \n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img  \n",
    "        labels[idx]=1 \n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    \n",
    "        labels[idx]=2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/300 \n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_norm, y_train, test_size=0.3, random_state=25)\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e302272d",
   "metadata": {},
   "source": [
    "### 이미지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "071cff18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨 :  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨 : ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51bef40",
   "metadata": {},
   "source": [
    "### 네트워크 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "a92b3a68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_78 (Conv2D)           (None, 26, 26, 512)       14336     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_78 (MaxPooling (None, 13, 13, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 11, 11, 256)       1179904   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_79 (MaxPooling (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_39 (Flatten)         (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 200)               1280200   \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 3)                 603       \n",
      "=================================================================\n",
      "Total params: 2,475,043\n",
      "Trainable params: 2,475,043\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(512, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(256, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(200, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4976be5",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "aa7552f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 1.3656 - accuracy: 0.2667 - val_loss: 1.1173 - val_accuracy: 0.3000\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.1100 - accuracy: 0.3476 - val_loss: 1.1097 - val_accuracy: 0.3000\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.0982 - accuracy: 0.3476 - val_loss: 1.1012 - val_accuracy: 0.3000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.0969 - accuracy: 0.3476 - val_loss: 1.0968 - val_accuracy: 0.3000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.0977 - accuracy: 0.3476 - val_loss: 1.0975 - val_accuracy: 0.3000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.0913 - accuracy: 0.3476 - val_loss: 1.0919 - val_accuracy: 0.3000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.0866 - accuracy: 0.3762 - val_loss: 1.0868 - val_accuracy: 0.3333\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.0902 - accuracy: 0.4095 - val_loss: 1.0832 - val_accuracy: 0.7000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.0852 - accuracy: 0.6952 - val_loss: 1.0760 - val_accuracy: 0.6889\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.0778 - accuracy: 0.6048 - val_loss: 1.0673 - val_accuracy: 0.3444\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.0684 - accuracy: 0.3381 - val_loss: 1.0748 - val_accuracy: 0.3000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.0558 - accuracy: 0.3476 - val_loss: 1.0550 - val_accuracy: 0.3000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.0305 - accuracy: 0.3810 - val_loss: 1.0138 - val_accuracy: 0.8556\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.0123 - accuracy: 0.7048 - val_loss: 0.9813 - val_accuracy: 0.6333\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.9761 - accuracy: 0.6952 - val_loss: 0.9502 - val_accuracy: 0.7333\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.9248 - accuracy: 0.8429 - val_loss: 0.8767 - val_accuracy: 0.8778\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8632 - accuracy: 0.8905 - val_loss: 0.7964 - val_accuracy: 0.7667\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.7802 - accuracy: 0.7143 - val_loss: 0.6953 - val_accuracy: 0.8222\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.7173 - accuracy: 0.6905 - val_loss: 0.6063 - val_accuracy: 0.8222\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5778 - accuracy: 0.8810 - val_loss: 0.4937 - val_accuracy: 0.8778\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4863 - accuracy: 0.8762 - val_loss: 0.5419 - val_accuracy: 0.8111\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4745 - accuracy: 0.8571 - val_loss: 0.4031 - val_accuracy: 0.8556\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4330 - accuracy: 0.8381 - val_loss: 0.3122 - val_accuracy: 0.9000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2915 - accuracy: 0.9429 - val_loss: 0.3138 - val_accuracy: 0.9222\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2644 - accuracy: 0.9333 - val_loss: 0.2765 - val_accuracy: 0.9000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1918 - accuracy: 0.9429 - val_loss: 0.2035 - val_accuracy: 0.9111\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1857 - accuracy: 0.9238 - val_loss: 0.1524 - val_accuracy: 0.9556\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1217 - accuracy: 0.9667 - val_loss: 0.1273 - val_accuracy: 0.9778\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0946 - accuracy: 0.9905 - val_loss: 0.0964 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0904 - accuracy: 0.9857 - val_loss: 0.1002 - val_accuracy: 0.9778\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0706 - accuracy: 0.9905 - val_loss: 0.0652 - val_accuracy: 0.9889\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0459 - accuracy: 0.9952 - val_loss: 0.0566 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9778\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0664 - accuracy: 0.9714 - val_loss: 0.0506 - val_accuracy: 0.9778\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.0549 - val_accuracy: 0.9778\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 9.9927e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 9.8177e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 9.6822e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 9.3610e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 9.1210e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 9.0407e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 8.8409e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 8.7274e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 8.8166e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdbec46ab20>"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=100, validation_data=(x_valid, y_valid), batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e735ad",
   "metadata": {},
   "source": [
    "# 시험용 데이터\n",
    "### 데이터 불러오기 + Resize하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "f38177e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 테스트 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor_train_test\"\n",
    "\n",
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 테스트 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "7732697e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 테스트 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock_train_test\"\n",
    "\n",
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 테스트 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "6e3296c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 테스트 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper_train_test\"\n",
    "\n",
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 테스트 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f54a148",
   "metadata": {},
   "source": [
    "### 폴더 별 라벨링 & 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "4a989919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시험용데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=300):\n",
    "    img_size=28\n",
    "    color=3\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor_train_test/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img  \n",
    "        labels[idx]=0  \n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock_train_test/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img  \n",
    "        labels[idx]=1 \n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper_train_test/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    \n",
    "        labels[idx]=2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"시험용데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/300\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55130793",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "757c4e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 357.1061 - accuracy: 0.5800\n",
      "test_loss : 357.1060791015625\n",
      "test_accuracy : 0.5799999833106995\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose = 2)\n",
    "print(\"test_loss : {}\".format(test_loss))\n",
    "print(\"test_accuracy : {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bb1c6d",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a5d02c",
   "metadata": {},
   "source": [
    "정확도를 높이기 위해 다양한 방법을 시도해보고 구글링도 해보았다.\n",
    "학습용 데이터로 학습할 때는 높게 나오지만 시험용 데이터로 확인해볼 땐 30% 근처를 자꾸 맴돈다. 그래서 시도한 방법은 다음과 같다. ① 학습용 데이터 수를 300개 → 900개로 늘려서 진행 ② 학습 반복 횟수(epoch)를 늘림 ③ 데이터를 train, validation, test로 분리함 ④ 하이퍼 파라미터, 필터 수를 늘림"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aad0bac",
   "metadata": {},
   "source": [
    "① 총 4명(각 300개 총 1200개)의 데이터로 학습 및 테스트를 해보았다. 학습용 데이터는 900개, 시험용 데이터는 300개로 진행을 하였는데 여전히 정확도가 낮았다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e52312",
   "metadata": {},
   "source": [
    "② epoch를 늘렸지만 늘릴수록 overfitting(과적합)이 나와서 테스트 시 정확도를 높일 수 없었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae5cdc3",
   "metadata": {},
   "source": [
    "③ 데이터를 trian, validation, test로 분리하여 진행하였다. 분리하여 진행하고 난 뒤 정확도가 이전에 비해 올라간 것을 확인할 수 있었다. 나름 정확도 높이는데에 도움이 되었다고 판단된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b6f0b1",
   "metadata": {},
   "source": [
    "④ 하이퍼 파라미터 값을 2의 제곱 수 만큼 높이면서 정확도를 확인하였다. 한 단계씩 높이면서 확인해보았는데, 정확도가 이전에 비해 조금 올랐다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a8222b",
   "metadata": {},
   "source": [
    "▶▶ 한 가지 의문이 드는 건, 매번 똑같은 코드로 실행을 해도 정확도가 달라진다는 점이다. 정확도가 70%까지 갔다가 다시 30%로 내려가기도 한다. 왜 이렇게 되는 지, 무언가가 잘못되었기에 그런건지 매우 궁금해진다. 또, 프로젝트를 하면서 궁금했던 점은 과적합을 막는 방법이다. 여러가지 방법들이 있긴 했지만 적용하는 것이 쉽지가 않았다. 이 부분을 좀 더 공부해야겠다는 생각이 들었다. 꾸준한 수치로 정확도가 나왔으면 했지만 그렇지 않아서 아쉽고 다같이 해당 프로젝트의 정확도를 높이는 방법에 대해 이야기하고 결과를 내고 싶다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f4ed6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
